
\documentclass{report}

\usepackage[utf8]{inputenc} % un package
\usepackage[T1]{fontenc}      % un second package
\usepackage[french]{babel}  % un troisiÃ¨me package
\usepackage{hyperref}
\usepackage{color}
\usepackage{amsmath}
\usepackage{amssymb}
\setcounter{secnumdepth}{5}
\setcounter{tocdepth}{5}

\makeatletter
\renewcommand{\thesection}{%
  \ifnum\c@chapter<1 \@arabic\c@section
  \else \thechapter.\@arabic\c@section
  \fi
}
\makeatother

\newcommand{\myparagraph}[1]{\paragraph{#1}\mbox{}\\}


\begin{document}

\maketitle

\section{Introduction}
Our task consist in predicting a binary label that was given to movies reviews. The review is labeled 1 when it is considered positive and 0 when considered negative. To complete this task, we will start with a relatively simple model, and then analyze the misclassified reviews. The size of our training dataset is 25,000. Simple models have an accuracy close to 90 \%. Therefore, if we train on 80\% of the training dataset and evaluate on the remaining 5,000, we could collect 500 misclassified reviews.
\\
Therefore, we don't want to read the mislabeled movie reviews one by one. Even if a focused human might not be able to classify every movie review correctly (If the commenter write a seemingly negative review but gives it a good rate) - which means that there might be Bayes noise in the dataset -, we have to try to understand what patterns in the data are still not captured by our model. 

If the model used yields a probability of belonging to a specific class, we could analyze the one that were misclassified and had the highest probability of belonging to the class that was wrongly predicted.

Then we can read a small subset of the wrongly classified observations and try to verify hypotheses related to the unindentified patterns.


\section{First model : TF-IDF on raw data}

Logistic Regression with stochastic gradient descent seems to yield the best results (If you google "state-of-the-art" sentiment classification, you can find an answer by olivier grisel which states that logistic regression is used by twitter engineers to classify tweets with the same binary labels).\\

What features should we use ?

\begin{itemize}
	\item TF-IDF
	\item TW-IDF
	\item Extra handcrafted features
\end{itemize} 


First, we tried to implement a TF-IDF on raw data, without preprocessing.
We tested several machine learning models :
\begin{itemize}
	\item MultinomialNB : our reference model
	\item BernoulliNB
	\item Linear SVC
	\item RandomForest : takes a long time of computation and not great results....
	\item RidgeClassifier
	\item k-NN
	\item Perceptron
	\item Logisitic Regression
	\item SGD Classifier
	\item Passive Aggressive Classifier : best results 
\end{itemize} 

Then, we selected the best features by implemententing a $\chi^2$-test on our first TF-IDF matrix.

We took only 3 different feature models on with SGD Classifer and Passive Aggressive Classifier :
\begin{itemize}
	\item 100K features
	\item 800K features
	\item 2M features
\end{itemize} 

Eventually, the best score we got was with Passive Aggressive Classifier and 800K features.

\section{Analysis of the wrongly classified observations}

ROC curve using probability of being wrongly classified ???

\section{Second Model : add preprocessing of the data}

\subsection{Tokenizer}

\subsection{Handcrafted features}

\section{Analysis of the wrongly classified observations}

ROC curve using probability of being wrongly classified ???

\section{Third Model : Add Graph of Words}

\end{document}


